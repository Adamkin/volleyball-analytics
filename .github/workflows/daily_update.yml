name: Daily Data Update

on:
  schedule:
    # Runs at 02:00 UTC (03:00 CET) every day
    - cron: '0 2 * * *'
  workflow_dispatch: # Allows you to click a button to run it manually

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Gives permission to save the new CSVs
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install libraries
        run: |
          pip install -r requirements.txt

      - name: Run Scraper
        run: python update_data.py

      - name: Commit and push if changed
        run: |
          git config --global user.name 'Automated Scraper'
          git config --global user.email 'scraper@bot.com'
          git add data/*.csv
          # Only commit if there are actual changes
          git diff --quiet && git diff --staged --quiet || (git commit -m "ðŸ¤– Daily data update" && git push)